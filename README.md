# SignSoul.AI
# ğŸ§  SignSoul.ai â€” Real-Time Sign Language to Speech Converter

SignSoul.ai is an AI-powered sign language interpreter designed to help the deaf and mute community communicate more naturally. This system captures hand gestures via webcam, classifies them using a trained CNN model, and converts recognized signs into speech â€” all in real-time and directly from the browser.

![SignSoul Logo](logo.png) <!-- Replace with actual logo path -->

---

## ğŸ” Project Overview

- ğŸ–ï¸ **Input:** Live hand gestures (Aâ€“Z + 10 common signs)
- ğŸ¯ **Goal:** Translate sign language into **spoken audio**
- ğŸ–¥ï¸ **Tech:** MediaPipe + TensorFlow/Keras + HTML/CSS/JS
- ğŸŒ **Deployment:** Browser-based (TensorFlow.js in progress)
- ğŸ“£ **Output:** Audio response using Web Speech API or pyttsx3

---

## ğŸ’¡ Features

- âœ… Real-time gesture recognition using webcam
- ğŸ¨ Clean, interactive front-end UI (`sign.html`)
- ğŸ§  Custom-trained CNN model (.h5)
- ğŸ”Š Instant text-to-speech conversion
- ğŸ’» Offline functionality (no Flask required)
- ğŸ”„ Future support for multilingual output & dynamic gestures

---

## ğŸ§° Tech Stack

| Component           | Tool/Library         |
|--------------------|----------------------|
| Programming        | Python, JavaScript   |
| CV & Tracking      | MediaPipe Hands      |
| Model Training     | TensorFlow, Keras    |
| Speech Output      | Web Speech API / pyttsx3 |
| Frontend           | HTML, CSS, JavaScript|
| Model Deployment   | (In progress) TensorFlow.js |

---

## ğŸ“ Folder Structure

â”œâ”€â”€ sign.html # Main frontend â”œâ”€â”€ static/ # CSS and assets â”œâ”€â”€ model/ # Trained CNN model (.h5) â”œâ”€â”€ scripts/ # JS for webcam & prediction â”œâ”€â”€ app.py # (Optional) Flask backend (deprecated) â”œâ”€â”€ requirements.txt # Python dependencies â””â”€â”€ README.md # Project documentation

yaml
Copy
Edit

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/SignSoul.ai.git
cd SignSoul.ai
2. Install Python Dependencies
bash
Copy
Edit
pip install -r requirements.txt
3. Run (Optional - Flask)
bash
Copy
Edit
python app.py
4. Run Frontend Only (Recommended)
Just open sign.html in your browser.
Ensure webcam permissions are enabled.

ğŸ“Š Model Details
Input Size: 64Ã—64 RGB images

Classes: Aâ€“Z + 10 frequent sign phrases

Accuracy: 91.8%

F1 Score: 91.4%

Training: 80/20 Train-Test Split

Frameworks: TensorFlow + Keras

ğŸ“½ï¸ Demo
ğŸ‘‰ [Live Demo (if hosted)]
ğŸ“¹ Demo will be shown live during project presentation.

ğŸ”® Future Enhancements
â• Add dynamic gesture recognition (LSTM/Transformer)

ğŸŒ Multilingual speech output (Hindi, Tamil, etc.)

ğŸ“² Mobile-ready deployment

ğŸ˜Š Facial expression detection

ğŸ§‘â€ğŸ« Sign-learning dashboard for users

ğŸ—£ï¸ Add reverse flow: Speech-to-sign translation

ğŸ‘©â€ğŸ’» Contributors
Ankita Mundra (RA2311003011145)

Rishika Dhanuka (RA2311003011165)

Vaidehi Mishra (RA2311003011168)

ğŸ“œ License
This project is licensed under the MIT License.

â­ Support Us
If you like this project, star â­ the repo and share your feedback!
Letâ€™s build a more inclusive digital world together ğŸ’™


---

Let me know if you want me to generate:
- A `requirements.txt`
- A demo GIF or YouTube link preview code
- A deployment guide or badge for TensorFlow.js

All the best for your GitHub upload and the review! ğŸ’ª
